---
title: "CUNY SPS DATA 621 - CTG5 - HW3"
author: "Betsy Rosalen, Gabrielle Bartomeo, Jeremy O'Brien, Lidiia Tronina, Rose Koh"
date: "April 10th, 2019"
output:
    bookdown::pdf_document2:
        toc: true
        toc_depth: 2
        number_sections: true
        fig_width: 5
        fig_height: 4
        fig_caption: true
        includes:  
            in_header: ./source/figure_placement.tex
        highlight: haddock
        df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy = FALSE, echo=FALSE, message=FALSE, warning=FALSE)
chooseCRANmirror(graphics=FALSE, ind=1)
source("./source/libs.R")
source("./source/script.R")
source("./source/captioner.R")
#set.seed(123)
```


\newpage


# DATA EXPLORATION

Relocating to a new city or state can be very stressful. In addition to the stress of packing and moving, you may also be nervous about moving to an unfamiliar area. To better understand their new community, some new residents or people interested in moving to a new city choose to review crime statistics in and around their neighborhood. Crime rate may also influence where people choose to live, raise their families and run their businesses; many potential new residents steer clear of cities with higher than average crime rates.

Data was collected in order to predict whether the neighborhood will be at risk for high crime levels. For each neighborhood the response variable, `target`, represents whether the crime rate is above the median crime rate or not.  In addition to that 13 predictor variables were collected representing each neighborhood's: proportion of large lots, non-retail business acres, whether or not it borders the Charles River, nitrogen oxides concentration, average number of rooms per dwelling, proportion of owner-occupied units, distances to five Boston employment centers, accessibility to radial highways, property tax rate, pupil-teacher ratio, proportion of African Americans, percent lower status, and median value of homes. The evaluation data contains the same 13 predictor variables and no target variable so it will be impossible to check the accuracy of our predictions from the testing data.  

```{r t1}
knitr::kable(variable_descriptions, caption="Data Dictionary")
```


\newpage


## Summary Statistics

```{r t2}
knitr::kable(sum_stat, caption="Summary statistics")
```

Looking at the `r t.ref("t2")`, we can see that `chas` and `target` are binary variables. 49% of our target variable is coded as 0's indicating that the crime rate is NOT above the median crime rate. There are potential outliers present in `zn`, `lstat`, `medv` and `dis`. 

## Shape of Predictor Distributions

`r f.ref("f1")` shows that the distribution of most of the variables seems skewed. There are some outliers in the right tail of `tax` , `rad`, `medv`, `lstat`, `dis` and left tail of `ptratio`. 

Even more interestingly, for many of the predictor variables the shape of the distribution is significantly different depending on the value of the `target`.  For example, `age` is highly left skewed for homes where the crime rate is above the median crime rate (`target` = 1) while the distribution for homes where the crime rate is not above the median the distribution is normal.  Other variables with similar differences are `dis`, `indus`, `lstat`, `nox`, `ptratio`, `rad`, and `tax`.

The variable `rad` has a clear separation at about a value of 5 with almost all homes with a `rad` value less than five being in the target group coded 0 and almost all homes with a `rad` value greater than five being in the target group coded 1.  Possibly indicating that a transformation into a categorical dummy variable might be desirable.  `indus` has a similar separation at a value of about 16, but not as strikingly.

```{r f1, fig.width=8, fig.cap="Data Distributions"}
Hist_new
```

## Outliers

`r f.ref("f2")` shows that there are also a large number of outliers that need to be accounted for, most significantly in `zn` and `medv` and less significantly in `lstat`, `dis` and `rm`. Since `tax` variable has values which are very large compared to other variables in the dataset, it was scaled to fit the boxplot by dividing by 10. 

```{r f2, fig.width=8, fig.cap="Boxplots highlighting many outliers in the data."}
outlier.boxplot
```

## Missing Values

There are no missing values in any of our observations gathered across the thirteen predictor variables as can be seen in `r f.ref("f3")`.


```{r f3, fig.height=3, fig.width=3, fig.cap="Missing values"}
na.barplot
```

## Linearity

Each variable was plotted against the target variable in order to determine at a glance which had the most potential linearity before the dataset was modified.

As can be observed in `r f.ref("f4")`, all of the predictor variables seem to have an impact on the target.  With most of them having a positive impact indicating that the higher the predictor variable values are more likely to correspond to a target that is coded as 1 indicating the crime rate is above the median.  The exceptions are `dis`, `medv`, `rm`, `zn`, and possibly `chas` where the distribution of predictor variable values is higher when the target is coded 0.

We can also see that many of the predictor variables have very different variances for the two values of the target.  This is especially true for `age`, `rad`, `tax`, and `zn` and less significantly for `dis` and `nox`.

```{r f4, fig.height=8, fig.width=8, fig.cap="Linear relationships between each predictor and the target"}
boxplots
```


\newpage


# DATA PREPARATION

## Missing Values and NA Imputation

Given that the training dataset does include missing values, there's no need to make systematic corrections or imputations.

## Dealing with outliers, leverage, and influence points

While logistic regression can be more robust to leverage points (explanatory variable values, which are distant on the x-axis), outliers (response variable values, which are distant on the y-axis) can exert influence which affects the curve and accuracy of target predictions.   

- `dis`, `tax` (property tax rate per $10k), and `medv` (median value of owner-occupied homes) see a few outliers and leverage points in both target classes 
- `indus` (the non-retail business acreage proportion) and `lstat` (percent lower status population) both have outliers in the below-mean (0) class
- `ptratio` (pupil-teacher ratio) fit is very impacted by density of low values in the above-mean class, making the linear relationship appear parabolic
- `rad` (highway access index) is influenced by a high-value concentration of locations distant from radial highways that fall in the above-mean class
- `rm` (average rooms per dwelling) sees a wider distribution of house size for the above-mean class then the below-mean; while `zn` (large-lot zoned land proportion) sees the opposite, with a concentration around a few non-residential land proportions for the above-mean class and a wide dispersion for the below-mean class

The figures below examine the linear relationships after a log transformation, which smoothes several relationships but still demonstrates visible influence for several other variables: `lstat`, `medv`, `ptratio`, `rad`, `rm`, `tax`, and `zn`.  We discuss further in the feature engineering section below.

```{r f6, fig.width=8, fig.cap="Natural log transformed predictor distributions"}
Hist_log_new
```

```{r f5, fig.height=8, fig.width=8, fig.cap="Relationships between natural log transformed predictors and the target"}
linearity_log_new
```


\newpage


## Correlation

An examination of correlation between the explanatory variables reveals the following:

- `indus` (non-retail business acre proportion) is positively correlated with `nox` (pollution concentration, $r = .76$) and `tax` (property tax rate per \$10k, $r = .73$) and is negatively correlated with `dis` (weighted mean distance to employment centers, $r = -.7$)
- `chas` (bordering Charles river) correlated with `nox` ($r = .97$) and `rm` (average rooms per dwelling, $r = .91$) and `age` (proportion of pre-1940 homes, $r = .79$); and is negatively correlated with `dis` ($r = -.97$)
- `medv` (median value of owner-occupied homes) is correlated with `rm` ($r = .71$); and is negatively correlated with `lstat` (percent lower status population, $r = -.74$)
- `age` is correlated with `nox` ($r = .74$); and is negatively correlated with `dis` ($r = -.75$)
- `rad` (highway access index) correlated with `tax` ($r = .91$)

```{r f7}
#Not sure why this doesn't work if you put it in the script file...
train %>% 
  select(-target) %>% 
  cor() %>% 
  round(2) %>% 
  corrplot(method = "circle")
```

```{r t3}
kable(correl2, caption="Correlation between predictors")
```


## Feature Engineering

In 'A Modern Approach to Regression with R' (page 284), Sheather quotes Cook and Weisberg, suggesting that the best way to determine need for log transformation of skewed predictors is to include both the original and transformed variables in the logistic regression model in order assess their relative contributions directly and prune accordingly

Reexamining the histograms of the predictor distributions above reveals that:

- `age` is left-skewed
- `dis` is right-skewed, and `zn` is extremely so
- `nox` is right-skewed and platykurtic (thin-tailed)
- `rad` and `tax` seem to have normal distributions, with large numbers of outliers at particular levels
- `indus` and `ptratio` reveal peculiar skew, with incidences at particular high level, perhaps due to regulation or infrastructure requirements

We include log transforms of `age`, `dis`, `nox`, `rad`, `tax`, `indus`, and `ptratio` in the dataset for evaluation in models.  


\newpage


# BUILD MODELS

## Model 1 - Base Model

The First model is a binary logistic model including all the explanatory variables.  The data is centered and scaled based on the mean and standard deviation of the variables.

```{r t4}
mod1_summary
```

The residual deviance is 192.05 and the AIC is 218.05. We will consider this as the baseline for all models. 

$$
\begin{aligned}
\widehat{y} = & 2.33 -1.54 \texttt{zn} -0.44 \texttt{indus} + 0.23 \texttt{chas} + 5.73 \texttt{nox} -0.41 \texttt{rm} + 0.97 \texttt{age} \\
& + 1.55 \texttt{dis} + 5.79 \texttt{rad} -1.04 \texttt{tax} + 0.88 \texttt{ptratio} + 0.33 \texttt{lstat} + 1.67 \texttt{medv}
\end{aligned}
$$

### Variance Inflation Factors

```{r t5}
knitr::kable(vif(mod.1$finalModel), caption="Variance Inflation Factors for Model 1")
```

The review of the VIF output suggests that some variables are highly collinear and may not be necessary to build a model.

```{r f8, fig.cap="Model 1 ROC Curve"}
plot(roc(train$target, pred.1.raw), main="ROC Curve")
```

```{r f9}
kable(auc(roc(train$target, pred.1.raw)), caption="Area Under the Curve")
```


\newpage


## Model 2 - Log Transform Skewed Predictors and Automated Selection Tools

The second model is a binary logistic model including all the explanatory variables plus log transformations of our skewed variables `age`, `dis`, `nox`, `rad`, `tax`, `indus`, and `ptratio` as recommended by Sheather in 'A Modern Approach to Regression with R'.

```{r t6}
summary(model.2.raw)
```

### Refining with the step function

Using the step function to try to refine this model by removing unnecessary variables leaves us with the following model.

```{r}
summary(model.2.step)
```

### Refining further with backward elimination

Since `log(nox)` has such a high p-value removing it from the model doesn't change the model much.  

```{r}
mod2_summary
```

So our final equation for the second model is:

$$
\begin{aligned}
\widehat{y} = & - 111.79 + 0.28 \texttt{indus} + 44.58 \texttt{nox} - 1.54 \texttt{rm} + 0.11 \texttt{age} \\
& - 2.30 \texttt{dis} + 1.32 \texttt{rad} - 0.18 \texttt{tax} + 5.87 \texttt{ptratio} + 0.24 \texttt{medv} \\
& - 4.01 \texttt{log(age)} + 11.12 \texttt{log(dis)} + 52.55 \texttt{log(tax)} - 91.86 \texttt{log(ptratio)}
\end{aligned}
$$

```{r fig.cap="Model 2 ROC Curve"}
plot(roc(train$target, pred.2.raw), main="ROC Curve")
```

```{r}
kable(auc(roc(train$target, pred.2.raw)), caption="Area Under the Curve")
```


\newpage


## Model 3 - Examine all possible interactions

For Model 3 we started with a strategy suggested by Faraway in 'Extending the Linear Model with R' that adds all possible interactions between the predictor variables in addition to the full set of predictors then uses the step function to remove unnecessary variables or interactions.  The resulting model is as follows:

```{r}
mod5_summary
```

Although we got the best AIC (72) and residual deviance numbers with this model, the coefficients are all insanely large and so are the p-values with not a single one showing any significance.  This is a good example of an extremely over-fitted model.  It probably models our training data perfectly, but would perform very poorly at predicting our test data.  

```{r fig.cap="Model 3 ROC Curve"}
plot(roc(train$target, pred.5.raw), main="ROC Curve")
```

```{r}
kable(auc(roc(train$target, pred.5.raw)), caption="Area Under the Curve")
```


\newpage


## Model 4 - Segmented/Piecewise Regression

Model 4 uses a broken stick approach based on the evidence we saw in the predictor distributions that indicated that splitting `rad` at a value of 5 would separate most 0's from 1's in our target.  We also included the log transformed variables that remained at the end of the model 2 selection process and interaction terms for the variables that showed the greatest correlation in our correlation plot which we will later narrow down using the step function.

```{r}
summary(model.6.raw)
```

Clearly separating the data based on splitting the `rad` variable at a value of 5 showed a great improvement in the model.  The two `rad` predictors for values 5 and above or less than 5 are by far the two most significant predictors in our model.  There are still a lot of variables with very low significance though and the model could definitely use some refinement.

### Backward Elimination vs. Forward Selection

We tried using using the step function for both forward selection and backward elimination and found that the backward elimination process resulted in the better model.  There were still some variables that appeared to be adding little value to the model however, so we removed `dis`, then `medv`, then the intercept resulting in the final model below.

### Final Model

```{r}
mod6_summary
```

So our final equation for the fourth model is:

$$
\begin{aligned}
\widehat{y} &= 0 + 3.01 \texttt{rad (less than 5)} + 1.80 \texttt{rad (five and over)} - 0.15 \texttt{zn} \\
& + 0.53 \texttt{indus} + 32.55 \texttt{nox} - 3.59 \texttt{rm} + 0.10 \texttt{age} - 0.22 \texttt{tax} + 10.87 \texttt{ptratio} + 11.52 \texttt{log(dis)} \\
& + 69.02 \texttt{log(tax)} - 190.90 \texttt{log(ptratio)} - 0.18 \texttt{indus:dis} + 0.04 \texttt{rm:medv} + -0.02 \texttt{age:dis}
\end{aligned}
$$

```{r fig.cap="Model 4 ROC Curve"}
plot(roc(train$target, pred.6.raw), main="ROC Curve")
```

```{r}
kable(auc(roc(train$target, pred.6.raw)), caption="Area Under the Curve")
```


### Marginal Model Plots

```{r fig.height=7, fig.width=8}
mmps(model.6, layout = c(4, 3))
```

# SELECT MODELS

```{r t13}
knitr::kable(eval_mods, caption = "Confusion Matrix Summary Statistics")
```

The four models were explored in order to determine the best way to determine whether or not a neighborhood's crime rate was above or below the median crime rate. It has been established that the most efficient model was the fourth model, with the first model being somewhat efficient, and the third over-fitted model being least efficient.

## Pseudo R2

There is no  $R^2$ for logistic regression to further evaluate, however, there is an alternative called $pseudo R^2$ terms that can be used for evaluation.

```{r t14}
knitr::kable(pseudo.r2, caption="Pseudo R2")
```

All of these measures and especially McFadden support the anova test's conclusion that model 4.

## Summary diagnostic plots

```{r fig.cap="Model 4 Summary diagnostic plots"}
par(mfrow=c(2,2))
plot(model.6)
```

# Appendix

The appendix is available as script.R file in `project3_crime` folder.

https://github.com/betsyrosalen/DATA_621_Business_Analyt_and_Data_Mining

```
# Load libs

if (!require('car')) (install.packages('car'))
if (!require('data.table')) (install.packages('data.table'))
if (!require('ggplot2')) (install.packages('ggplot2'))
if (!require('caret')) (install.packages('caret'))
if (!require('corrplot')) (install.packages('corrplot'))
if (!require('data.table')) (install.packages('data.table'))
if (!require('DataExplorer')) (install.packages('DataExplorer'))
if (!require('faraway')) (install.packages('faraway'))
if (!require('formattable')) (install.packages('formattable'))
if (!require('gridExtra')) (install.packages('gridExtra'))
if (!require('kableExtra')) (install.packages('kableExtra'))
if (!require('leaps')) (install.packages('leaps'))
if (!require('MASS')) (install.packages('MASS'))
if (!require('nnet')) (install.packages('nnet'))
if (!require('psych')) (install.packages('psych'))
if (!require('pROC')) (install.packages('pROC'))
if (!require('reshape')) (install.packages('reshape'))
if (!require('tidyverse')) (install.packages('tidyverse'))
if (!require('randomForest')) (install.packages('randomForest'))

# load data
train <- read.csv ('https://raw.githubusercontent.com/silverrainb/data621proj3/master/crime-training-data_modified.csv', stringsAsFactors = F, header = T)
test <- read.csv('https://raw.githubusercontent.com/silverrainb/data621proj3/master/crime-evaluation-data_modified.csv', stringsAsFactors = F, header = T)

variable_descriptions <- rbind(c('target','whether the crime rate is above the median crime rate (1) or not (0)','response'),
                               c('zn','proportion of residential land zoned for large lots (over 25000 square feet) ','predictor'),
                               c('indus','proportion of non-retail business acres per suburb','predictor'),
                               c('chas','a dummy var. for whether the suburb borders the Charles River (1) or not (0)','predictor'),
                               c('nox','nitrogen oxides concentration (parts per 10 million)','predictor'),
                               c('rm','average number of rooms per dwelling','predictor' ),
                               c('age','proportion of owner-occupied units built prior to 1940','predictor'),
                               c('dis','weighted mean of distances to five Boston employment centers','predictor'),
                               c('rad','index of accessibility to radial highways','predictor'),
                               c('tax','full-value property-tax rate per $10,000','predictor'),
                               c('ptratio','pupil-teacher ratio by town','predictor'),
                               c('black','1000(B_k - 0.63)^2 where B_k is the proportion of blacks by town','predictor'),
                               c('lstat','lower status of the population (percent)','predictor'),
                               c('medv','median value of owner-occupied homes in $1000s','predictor'))
colnames(variable_descriptions) <- c('VARIABLE','DEFINITION','TYPE')

# Summary Statistics
sum_stat <- describe(train)[,c(2,8,3,5,9,4)]

# Shape of Predictor Distributions
Hist_new <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x = val, fill=factor(target))) +
    geom_histogram(position="dodge", bins=10, alpha=0.5) +
    facet_wrap(~ var, scales = "free") +
    scale_fill_manual("target",values = c("#58BFFF", "#3300FF")) +
    xlab("") +
    ylab("") +
    theme(panel.background = element_blank())
  
  
# Outliers
boxplot_train <- train[,-13]
boxplot_train$tax <- boxplot_train$tax/10
melt.train <- melt(boxplot_train)

outlier.boxplot <- ggplot(melt.train, aes(variable, value)) +
  geom_boxplot(width=.5, fill="#58BFFF", outlier.colour="red", outlier.size = 1) +
  stat_summary(aes(colour="mean"), fun.y=mean, geom="point",
               size=2, show.legend=TRUE) +
  stat_summary(aes(colour="median"), fun.y=median, geom="point",
               size=2, show.legend=TRUE) +
  coord_flip(ylim = c(0, 110), expand = TRUE) +
  scale_y_continuous(labels = scales::comma,
                     breaks = seq(0, 110, by = 10)) +
  labs(colour="Statistics", x="", y="") +
  scale_colour_manual(values=c("#9900FF", "#3300FF")) +
  theme(panel.background=element_blank(), legend.position="top")


#  Missing Values
na.barplot <- plot_missing(train)

# Boxplots
boxplots <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x=factor(target), y=val)) +
    geom_boxplot(width=.5, fill="#58BFFF", outlier.colour="red", outlier.size = 1) +
    stat_summary(aes(colour="mean"), fun.y=mean, geom="point",
                 size=2, show.legend=TRUE) +
    stat_summary(aes(colour="median"), fun.y=median, geom="point",
                 size=2, show.legend=TRUE) +
    facet_wrap(~ var, scales = "free", ncol=4) +
    labs(colour="Statistics", x="", y="") +
    scale_colour_manual(values=c("#9900FF", "#3300FF")) +
    theme(panel.background=element_blank())

# DATA PREPARATION <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

# Correlation

correl2 <- train %>%
  select(-target) %>%
  cor() %>%
  round(2) %>%
  corrplot(method = "circle")
  
# Our transformation function
scaleFUN <- function(x) sprintf("%.2f", x)

Hist_log_new <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x = val, fill=factor(target))) +
    geom_histogram(position="dodge", bins=10, alpha=0.5) +
    facet_wrap(~ var, scales = "free") +
    scale_y_continuous(trans = "log", label=scaleFUN) +
    scale_fill_manual("target",values = c("#58BFFF", "#3300FF")) +
    xlab("") +
    ylab("") +
    theme(panel.background = element_blank())
  
# Linearity at log10 scale

linearity_log_new <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x=factor(target), y=val)) +
    geom_boxplot(width=.5, fill="#58BFFF", outlier.colour="red", outlier.size = 1) +
    scale_y_continuous(trans = "log", label=scaleFUN) +
    stat_summary(aes(colour="mean"), fun.y=mean, geom="point",
                 size=2, show.legend=TRUE) +
    stat_summary(aes(colour="median"), fun.y=median, geom="point",
                 size=2, show.legend=TRUE) +
    facet_wrap(~ var, scales = "free", ncol=4) +
    labs(colour="Statistics", x="", y="") +
    scale_colour_manual(values=c("#9900FF", "#3300FF")) +
    theme(panel.background=element_blank())
    
# BUILD MODELS <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

## Model 1

## Build the model
model.1 <- glm(target ~ ., 
               family = binomial, 
               data = train) # + 0 removes intercept
# 
mod.1 <- train(target ~., data = train,
                 method = "glm",
                 family = "binomial",
                 preProcess = c("center", "scale")) # center and scale data based on the mean and sd

mod1_summary <- summary(mod.1)

### Model 1 Summary Statistics
pred.1.raw <- predict(mod.1, newdata = train)
pred.1 <- as.factor(ifelse(pred.1.raw < .5, 0, 1))
mod1.conf.mat <- confusionMatrix(pred.1,
                                 as.factor(train$target), mode = "everything")

#====================================================================================================================#
## Model 2

## Build the model
model.2.raw <- glm(target ~ zn + indus + chas + nox + rm + age + dis + rad + tax +
                     ptratio + lstat + medv + log(age) + log(dis) + log(nox) +
                     log(rad) + log(tax) + log(indus) + log(ptratio),
               family = binomial,
               data = train)

model.2.step <- step(model.2.raw, trace=FALSE)

model.2 <- glm(target ~ indus + nox + rm + age + dis + rad + tax + ptratio + medv + 
                     log(age) + log(dis) + log(tax) + log(ptratio),
                     family = binomial, data = train)

mod2_summary <- summary(model.2)

#marg_mod_plot_2 <- mmps(model.2, layout=c(5,4), key=NULL) # library car

### Model 2 Summary Statistics
pred.2.raw <- predict(model.2, newdata = train)
pred.2 <- as.factor(ifelse(pred.2.raw < .5, 0, 1))
mod2.conf.mat <- confusionMatrix(pred.2,
                                 as.factor(train$target), mode = "everything")

#====================================================================================================================#

## Model 3

#big_mod5 <- glm(target ~ (zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + lstat + medv)^2,
#               data = train, family = binomial)

#small_mod5 <- step(big_mod5, trace=FALSE)

# The above code is VERY computationally expensive
# Here's the result so it doesn't need to be run again.
model.5 <-  glm(formula = target ~ zn + indus + chas + nox + rm + age + dis +
                    rad + tax + ptratio + lstat + medv + zn:age + zn:tax + zn:ptratio +
                    zn:lstat + indus:chas + indus:rad + indus:ptratio + indus:medv +
                    nox:age + nox:tax + nox:ptratio + nox:lstat + nox:medv +
                    rm:age + age:tax + age:ptratio + dis:tax + dis:ptratio+
                    dis:lstat + dis:medv + rad:tax + tax:medv + lstat:medv, family = binomial,
                    data = train)

mod5_summary <- summary(model.5)

#resid_plot_5 <- residual.plots(model.5, exclude = 4, layout = c(2, 2)) # library car

#marg_mod_plot_5 <- mmps(model.5, span = 3/4, layout = c(2, 2)) # library car

### Model 5 Summary Statistics
pred.5.raw <- predict(model.5, newdata = train)
pred.5 <- as.factor(ifelse(pred.5.raw < .5, 0, 1))
mod5.conf.mat <- confusionMatrix(pred.5, as.factor(train$target), mode = "everything")


#====================================================================================================================#
## Model 4

## Build the model
less_than_five <- function(x) ifelse(x < 5, x, 0)
five_and_over <- function(x) ifelse(x >= 5, x, 0)

model.6.raw <- glm(target ~ (less_than_five(rad) + five_and_over(rad)) + zn + indus + chas + nox + 
                       rm + age + dis + tax + ptratio + lstat + medv + log(age) + 
                       log(dis) + log(tax) + log(ptratio) + indus:nox + indus:dis + 
                       indus:tax+ nox:age + nox:dis + rm:medv + dis:age,
                   family = binomial,
                   data = train)

backward.mod <- step(model.6.raw, direction = "backward", trace=FALSE)
backward_sum <- summary(backward.mod)

#forward.mod <- step(model.6.raw, direction = "forward", trace=FALSE)
#forward_sum <- summary(forward.mod)

model.6 <- glm(target ~ less_than_five(rad) + five_and_over(rad) +
                    zn + indus + nox + rm + age + tax + ptratio + 
                    log(dis) + log(tax) + log(ptratio) + indus:dis + rm:medv +
                    age:dis + 0, family = binomial, data = train) # + 0 removes intercept

mod6_summary <- summary(model.6)

### Model 6 Summary Statistics
pred.6.raw <- predict(model.6, newdata = train)
pred.6 <- as.factor(ifelse(pred.6.raw < .5, 0, 1))
mod6.conf.mat <- confusionMatrix(pred.6, as.factor(train$target), mode = "everything")

mod.6 <- train(target ~ less_than_five(rad) + five_and_over(rad) +
                 zn + indus + nox + rm + age + tax + ptratio + 
                 log(dis) + log(tax) + log(ptratio) + indus:dis + rm:medv +
                 age:dis + 0, 
               family = binomial, 
               data = train,
               method = 'glm') # + 0 removes intercept

#====================================================================================================================#

## Model Evaluations

eval_mods <- data.frame(mod1.conf.mat$byClass,
                   mod2.conf.mat$byClass,
                   mod5.conf.mat$byClass,
                   mod6.conf.mat$byClass) # add additional model stats

eval_mods <- data.frame(t(eval_mods))
row.names(eval_mods) <- c("Model.1", "Model.2", "Model.3", "Model.4") # add additional models

eval_mods <- dplyr::select(eval_mods, Sensitivity, Specificity, Precision, Recall, F1)


# SELECT MODELS <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#Pseudo R2

pseudo.r2 <- data.frame(pscl::pR2(model.1),
                        pscl::pR2(model.2),
                        pscl::pR2(model.5),
                        pscl::pR2(model.6)) 

pseudo.r2 <- data.frame(t(pseudo.r2))

row.names(pseudo.r2) <- c("Model.1", "Model.2", "Model.3", "Model.4")


```