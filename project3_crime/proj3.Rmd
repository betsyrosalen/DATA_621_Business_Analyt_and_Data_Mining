---
title: "CUNY SPS DATA 621 - CTG5 - HW3"
author: "Betsy Rosalen, Gabrielle Bartomeo, Jeremy O'Brien, Lidiia Tronina, Rose Koh"
date: "April 10th, 2019"
output:
    bookdown::pdf_document2:
        toc: true
        toc_depth: 2
        number_sections: true
        fig_width: 5
        fig_height: 4
        fig_caption: true
        includes:  
            in_header: ./source/figure_placement.tex
        highlight: haddock
        df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(tidy = FALSE, echo=FALSE, message=FALSE, warning=FALSE)
chooseCRANmirror(graphics=FALSE, ind=1)
source("./source/libs.R")
source("./source/script.R")
source("./source/captioner.R")
#set.seed(123)
```


\newpage


# DATA EXPLORATION

Relocating to a new city or state can be very stressful. In addition to the stress of packing and moving, you may also be nervous about moving to an unfamiliar area. To better understand their new community, some new residents or people interested in moving to a new city choose to review crime statistics in and around their neighborhood. Crime rate may also influence where people choose to live, raise their families and run their businesses; many potential new residents steer clear of cities with higher than average crime rates.

Data was collected in order to predict whether the neighborhood will be at risk for high crime levels. For each neighborhood the response variable, `target`, represents whether the crime rate is above the median crime rate or not.  In addition to that 13 predictor variables were collected representing each neighborhood's: proportion of large lots, non-retail business acres, whether or not it borders the Charles River, nitrogen oxides concentration, average number of rooms per dwelling, proportion of owner-occupied units, distances to five Boston employment centers, accessibility to radial highways, property tax rate, pupil-teacher ratio, proportion of African Americans, percent lower status, and median value of homes. The evaluation data contains the same 13 predictor variables and no target variable so it will be impossible to check the accuracy of our predictions from the testing data.  

```{r t1}
knitr::kable(variable_descriptions, caption="Data Dictionary")
```


\newpage


## Summary Statistics

```{r t2}
knitr::kable(sum_stat, caption="Summary statistics")
```

Looking at the `r t.ref("t2")`, we can see that `chas` and `target` are binary variables. 49% of our target variable is coded as 0's indicating that the crime rate is NOT above the median crime rate. There are potential outliers present in `zn`, `lstat`, `medv` and `dis`. 

## Shape of Predictor Distributions

`r f.ref("f1")` shows that the distribution of most of the variables seems skewed. There are some outliers in the right tail of `tax` , `rad`, `medv`, `lstat`, `dis` and left tail of `ptratio`. 

Even more interestingly, for many of the predictor variables the shape of the distribution is significantly different depending on the value of the `target`.  For example, `age` (proportion of owner-occupied units built prior to 1940) is highly left skewed for homes where the crime rate is above the median crime rate (`target` = 1), while for homes where the crime rate is not above the median (`target` = 0) the distribution is normal.  This indicates that areas with a higher proportion of older structures are more likely to have a crime rate above the median, which is what we would expect.  Other variables with similar differences are `dis`, `indus`, `lstat`, `nox`, `ptratio`, `rad`, and `tax`.

The variable `rad` has a clear separation at about a value of 5 with almost all homes with a `rad` value less than five being in the `target` group coded 0 and almost all homes with a `rad` value greater than five being in the `target` group coded 1.  Possibly indicating that a transformation into a categorical dummy variable might be desirable.  `indus` has a similar separation at a value of about 16, but not as strikingly.

```{r f1, fig.width=8, fig.cap="Data Distributions"}
Hist_new
```

## Outliers

`r f.ref("f2")` shows that there are also a large number of outliers that need to be accounted for, most significantly in `zn` (proportion of residential land zoned for large lots [over 25000 square feet]) and `medv` (median value of owner-occupied homes in $1000s) and less significantly in `lstat`, `dis` and `rm`. Since the `tax` variable has values which are very large compared to other variables in the dataset, it was scaled to fit the boxplot by dividing by 10. 

```{r f2, fig.width=8, fig.cap="Boxplots highlighting many outliers in the data."}
outlier.boxplot
```

## Missing Values

There are no missing values in any of our observations gathered across the thirteen predictor variables as can be seen in `r f.ref("f3")`.

```{r f3, fig.height=3, fig.width=3, fig.cap="Missing values"}
na.barplot
```

## Linearity

Each variable was plotted against the target variable in order to determine at a glance which had the most potential linearity before the dataset was modified.

As can be observed in `r f.ref("f4")`, all of the predictor variables seem to have an impact on the target.  With most of them having a positive impact indicating that the higher the predictor variable values are more likely to correspond to a target that is coded as 1 indicating the crime rate is above the median.  The exceptions are:

1. `dis`, weighted mean of distances to five Boston employment centers
2. `medv`, median value of owner-occupied homes in $1000s
3. `rm`, average number of rooms per dwelling
4. `zn`, proportion of residential land zoned for large lots (over 25000 square feet)
5. and possibly `chas`, a dummy var. for whether the suburb borders the Charles River (1) or not (0)

For these variables the distribution of predictor variable values is higher when the target is coded 0 for 'crime rate not above the median'.

We can also see that many of the predictor variables have very different variances for the two values of the target.  This is especially true for `age`, `rad`, `tax`, and `zn` and less significantly for `dis` and `nox`.  The presence of a large number of outliers `zn`, `medv`, `lstat`, `dis` and `rm` as noted above also becomes more apparent.  The large number of outliers in `age` which were hidden in the previous plot also become visible here.  

```{r f4, fig.height=8, fig.width=8, fig.cap="Linear relationships between each predictor and the target"}
boxplots
```


\newpage


# DATA PREPARATION

## Missing Values and NA Imputation

Given that (as noted above) the training dataset does not include any missing values, there's no need to make systematic corrections or imputations.

## Dealing with outliers, leverage, and influence points

While logistic regression can be more robust to leverage points (explanatory variable values, which are distant on the x-axis), outliers (response variable values, which are distant on the y-axis) can exert influence which affects the curve and accuracy of target predictions.   

- `dis`, `tax` (property tax rate per $10k), and `medv` (median value of owner-occupied homes) see a few outliers and leverage points in both target classes 
- `indus` (the non-retail business acreage proportion) and `lstat` (percent lower status population) both have outliers in the below-mean (0) class
- `ptratio` (pupil-teacher ratio) fit is very impacted by density of low values in the above-mean class, making the linear relationship appear parabolic
- `rad` (highway access index) is influenced by a high-value concentration of locations distant from radial highways that fall in the above-mean class and is almost a perfect predictor for our target with almost all values at 5 and above being coded 1 indicating they are above the median crime rate.
- `rm` (average rooms per dwelling) sees a wider distribution of house size for the above-mean class; while `zn` (large-lot zoned land proportion) sees the opposite, with a concentration around a few non-residential land proportions for the above-mean class and a wide dispersion for the below-mean class

The figures below examine the linear relationships after a log transformation, which smoothes several relationships but still demonstrates visible influence for several other variables: `lstat`, `medv`, `ptratio`, `rad`, `rm`, `tax`, and `zn`.  We discuss further in the feature engineering section below.

```{r f6, fig.width=8, fig.cap="Natural log transformed predictor distributions"}
Hist_log_new
```

```{r f5, fig.height=8, fig.width=8, fig.cap="Relationships between natural log transformed predictors and the target"}
linearity_log_new
```


\newpage


## Correlation

An examination of correlation between the explanatory variables reveals the following:

- `indus` (non-retail business acre proportion) is positively correlated with `nox` (pollution concentration, $r = .76$) and `tax` (property tax rate per \$10k, $r = .73$) and is negatively correlated with `dis` (weighted mean distance to employment centers, $r = -.7$)
- `chas` (bordering Charles river) correlated with `nox` ($r = .97$) and `rm` (average rooms per dwelling, $r = .91$) and `age` (proportion of pre-1940 homes, $r = .79$); and is negatively correlated with `dis` ($r = -.97$)
- `medv` (median value of owner-occupied homes) is correlated with `rm` ($r = .71$); and is negatively correlated with `lstat` (percent lower status population, $r = -.74$)
- `age` is correlated with `nox` ($r = .74$); and is negatively correlated with `dis` ($r = -.75$)
- `rad` (highway access index) correlated with `tax` ($r = .91$)

```{r f7}
#Not sure why this doesn't work if you put it in the script file...
train %>% 
  select(-target) %>% 
  cor() %>% 
  round(2) %>% 
  corrplot(method = "circle")
```

```{r t3}
kable(correl2, caption="Correlation between predictors")
```


## Feature Engineering

In 'A Modern Approach to Regression with R' (page 284), Sheather quotes Cook and Weisberg, suggesting that the best way to determine need for log transformation of skewed predictors is to include both the original and transformed variables in the logistic regression model in order assess their relative contributions directly and prune accordingly

Reexamining the histograms of the predictor distributions above reveals that:

- `age` is left-skewed
- `dis` is right-skewed, and `zn` is extremely so
- `nox` is right-skewed and platykurtic (thin-tailed)
- `rad` and `tax` seem to have normal distributions, with large numbers of outliers at particular levels
- `indus` and `ptratio` reveal peculiar skew, with incidences at particular high level, perhaps due to regulation or infrastructure requirements

We include log transforms of `age`, `dis`, `nox`, `rad`, `tax`, `indus`, and `ptratio` in the dataset for evaluation in models.  

We also looked at interactions between variables in two ways; first by including all possible interactions in one model, and then by choosing only the most highly correlated variables to include as interactions in a subsequent model.  

Finally, we also separated the observations with `rad` values at 5 and above vs. those with less than 5 to create a separate regression line in a segmented regression approach.

\newpage


# BUILD MODELS

## Model 1 - Base Model

The First model is a binary logistic model including all the explanatory variables.  The data is centered and scaled based on the mean and standard deviation of the variables.  The residual deviance is 192.05, AIC is 218.05, Pseudo-$R^2$ is 0.83 or 0.70 depending on which method you use for calculation. We will consider this as the baseline for all models. Two of the variables `rm` and `medv` have VIF values above the usual cutoff at 5 indicating that collinearity may be causing problems in our model.  We will address this in subsequent models.

```{r t4}
#mod1_summary
mod1_summary_a
```

$$
\begin{aligned}
\widehat{y} = & 2.33 -1.54 \texttt{zn} -0.44 \texttt{indus} + 0.23 \texttt{chas} + 5.73 \texttt{nox} -0.41 \texttt{rm} + 0.97 \texttt{age} \\
& + 1.55 \texttt{dis} + 5.79 \texttt{rad} -1.04 \texttt{tax} + 0.88 \texttt{ptratio} + 0.33 \texttt{lstat} + 1.67 \texttt{medv}
\end{aligned}
$$

```{r f8, fig.cap="Model 1 ROC Curve", fig.height=3, fig.width=3.5}
plot(roc(train$target, pred.1.raw), main="ROC Curve")
```

```{r f9}
kable(auc(roc(train$target, pred.1.raw)), caption="Area Under the Curve")
```


\newpage


## Model 2 - Log Transform Skewed Predictors and Automated Selection Tools

The second model is a binary logistic model including all the explanatory variables plus log transformations of our skewed variables `age`, `dis`, `nox`, `rad`, `tax`, `indus`, and `ptratio` as recommended by Sheather in 'A Modern Approach to Regression with R'.  We see considerably improved statistics below with higher Pseudo-$R^2$ values for both the (Craig-Uhler) and (McFadden) calculations and lower AIC and BIC values.  We see some very large VIF numbers though indicating that we have too many correlated variables in our model before refinement.  So we used the step function to refine our model next.

```{r t6}
#summary(model.2.raw)
mod2_summary_raw
```

### Refining with the step function and backward elimination

Using the step function to refine this model leaves us with the following model plus `log(nox)`.  Since `log(nox)` had such a high p-value we removed it from the model, which didn't change the model's performance much.  Although our Pseudo-$R^2$ values didn't change at all we see an improvement in both the AIC and BIC numbers in a much simpler and reduced model which is preferred for simplicity sake.

```{r}
#mod2_summary
mod2_summary_a
```

The equation for the simplified second model is:

$$
\begin{aligned}
\widehat{y} = & - 111.79 + 0.28 \texttt{indus} + 44.58 \texttt{nox} - 1.54 \texttt{rm} + 0.11 \texttt{age} \\
& - 2.30 \texttt{dis} + 1.32 \texttt{rad} - 0.18 \texttt{tax} + 5.87 \texttt{ptratio} + 0.24 \texttt{medv} \\
& - 4.01 \texttt{log(age)} + 11.12 \texttt{log(dis)} + 52.55 \texttt{log(tax)} - 91.86 \texttt{log(ptratio)}
\end{aligned}
$$

```{r fig.cap="Model 2 ROC Curve", fig.height=3, fig.width=3.5}
plot(roc(train$target, pred.2.raw), main="ROC Curve")
```

```{r}
kable(auc(roc(train$target, pred.2.raw)), caption="Area Under the Curve")
```


\newpage


## Model 3 - Examine all possible interactions

For Model 3 we started with a strategy suggested by Faraway in 'Extending the Linear Model with R' that adds all possible interactions between the predictor variables in addition to the full set of predictors then uses the step function to remove unnecessary variables or interactions.  The resulting model is on the following page.

```{r}
#mod5_summary
mod5_summary_a
```

Although we got the best AIC (72) and residual deviance, AIC, BIC and Pseudo-$R^2$ numbers with this model, the coefficients are all insanely large and so are the VIF's and the p-values with not a single one showing any significance.  This is a good example of an extremely over-fitted model.  It probably models our training data perfectly, but would perform very poorly at predicting our test data.  

```{r fig.cap="Model 3 ROC Curve", fig.height=3, fig.width=3.5}
plot(roc(train$target, pred.5.raw), main="ROC Curve")
```

```{r}
kable(auc(roc(train$target, pred.5.raw)), caption="Area Under the Curve")
```


\newpage


## Model 4 - Segmented/Piecewise Regression

Model 4 uses a 'segmented' or 'piecewise' approach based on the evidence we saw in the predictor distribution plots that indicated that splitting `rad` at a value of 5 would separate most 0's from 1's in our target.  We also included the log transformed variables that remained at the end of the model 2 selection process and interaction terms for the variables that showed the greatest correlation in our correlation plot which we will later narrow down using the step function.

```{r}
#summary(model.6.raw)
mod6_summary_raw
```

Clearly separating the data based on splitting the `rad` variable at a value of 5 showed a great improvement in the model with much better statistics all around. We still have some very high VIF numbers but those should be reduced after we refine the model by removing some of the variables.  The two `rad` predictors for values 5 and above or less than 5 are by far the two most significant predictors in our model.  There are still a lot of variables with very low significance though and the model could definitely use some refinement.

### Backward Elimination vs. Forward Selection

We tried using using the step function for both forward selection and backward elimination and found that the backward elimination process resulted in the better model.  There were still some variables that appeared to be adding little value to the model however, so we removed `dis`, then `medv`, then the intercept resulting in the final model below.

While we have much improved statistics over all, we still have some extremely high VIF numbers indicting a lot of collinearity in our model.  This is to be expected since we still have some original and log transformed versions of the same variable, or original and interaction terms that include that variable left in the same model.  

```{r}
#mod6_summary
mod6_summary_a
```

The equation for the fourth model is:

$$
\begin{aligned}
\widehat{y} &= 0 + 3.01 \texttt{rad (less than 5)} + 1.80 \texttt{rad (five and over)} - 0.15 \texttt{zn} \\
& + 0.53 \texttt{indus} + 32.55 \texttt{nox} - 3.59 \texttt{rm} + 0.10 \texttt{age} - 0.22 \texttt{tax} + 10.87 \texttt{ptratio} + 11.52 \texttt{log(dis)} \\
& + 69.02 \texttt{log(tax)} - 190.90 \texttt{log(ptratio)} - 0.18 \texttt{indus:dis} + 0.04 \texttt{rm:medv} + -0.02 \texttt{age:dis}
\end{aligned}
$$

```{r fig.cap="Model 4 ROC Curve", fig.height=3, fig.width=3.5}
plot(roc(train$target, pred.6.raw), main="ROC Curve")
```

```{r}
kable(auc(roc(train$target, pred.6.raw)), caption="Area Under the Curve")
```


### Marginal Model Plots

```{r fig.height=7, fig.width=8}
mmps(model.6, layout = c(4, 3))
```


# SELECT MODELS

```{r t13}
knitr::kable(eval_mods, caption = "Confusion Matrix Summary Statistics")
```

The four models were explored in order to determine the best way to determine whether or not a neighborhood's crime rate was above or below the median crime rate. It has been established that the most efficient model was the fourth model, with the first model being somewhat efficient, and the third over-fitted model being least efficient.

## Pseudo R2

There is no  $R^2$ for logistic regression to further evaluate, however, there is an alternative called $pseudo R^2$ terms that can be used for evaluation.

```{r t14}
knitr::kable(pseudo.r2, caption="Pseudo R2")
```

All of these measures and especially McFadden support the anova test's conclusion that model 4 is our most efficient and effective model for predicting whether a neighborhood will be at risk for a higher than median crime rate.

## Summary diagnostic plots

```{r fig.cap="Model 4 Summary diagnostic plots", fig.height=6, fig.width=6}
par(mfrow=c(2,2))
plot(model.6)
```


\newpage


# Appendix

The appendix is available as script.R file in `project3_crime` folder.

https://github.com/betsyrosalen/DATA_621_Business_Analyt_and_Data_Mining

```
# Load libs

if (!require('car')) (install.packages('car'))
if (!require('caret')) (install.packages('caret'))
if (!require('corrplot')) (install.packages('corrplot'))
if (!require('data.table')) (install.packages('data.table'))
if (!require('DataExplorer')) (install.packages('DataExplorer'))
if (!require('faraway')) (install.packages('faraway'))
if (!require('gridExtra')) (install.packages('gridExtra'))
if (!require('jtools')) (install.packages('jtools'))
if (!require('kableExtra')) (install.packages('kableExtra'))
if (!require('MASS')) (install.packages('MASS'))
if (!require('psych')) (install.packages('psych'))
if (!require('pROC')) (install.packages('pROC'))
if (!require('pscl')) (install.packages('pscl'))
if (!require('tidyverse')) (install.packages('tidyverse'))

# load data
train <- read.csv ('https://raw.githubusercontent.com/silverrainb/data621proj3/master/crime-training-data_modified.csv', stringsAsFactors = F, header = T)
test <- read.csv('https://raw.githubusercontent.com/silverrainb/data621proj3/master/crime-evaluation-data_modified.csv', stringsAsFactors = F, header = T)

variable_descriptions <- rbind(
   c('target','whether the crime rate is above the median crime rate (1) or not (0)','response'),
   c('zn','proportion of residential land zoned for large lots (over 25000 square feet) ','predictor'),
   c('indus','proportion of non-retail business acres per suburb','predictor'),
   c('chas','a dummy var. for whether the suburb borders the Charles River (1) or not (0)','predictor'),
   c('nox','nitrogen oxides concentration (parts per 10 million)','predictor'),
   c('rm','average number of rooms per dwelling','predictor' ),
   c('age','proportion of owner-occupied units built prior to 1940','predictor'),
   c('dis','weighted mean of distances to five Boston employment centers','predictor'),
   c('rad','index of accessibility to radial highways','predictor'),
   c('tax','full-value property-tax rate per $10,000','predictor'),
   c('ptratio','pupil-teacher ratio by town','predictor'),
   c('black','1000(B_k - 0.63)^2 where B_k is the proportion of blacks by town','predictor'),
   c('lstat','lower status of the population (percent)','predictor'),
   c('medv','median value of owner-occupied homes in $1000s','predictor'))
colnames(variable_descriptions) <- c('VARIABLE','DEFINITION','TYPE')

# Summary Statistics
sum_stat <- describe(train)[,c(2,8,3,5,9,4)]

# Shape of Predictor Distributions
Hist_new <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x = val, fill=factor(target))) +
    geom_histogram(position="dodge", bins=10, alpha=0.5) +
    facet_wrap(~ var, scales = "free") +
    scale_fill_manual("target",values = c("#58BFFF", "#3300FF")) +
    xlab("") +
    ylab("") +
    theme(panel.background = element_blank())
  
  
# Outliers
boxplot_train <- train[,-13]
boxplot_train$tax <- boxplot_train$tax/10
melt.train <- melt(boxplot_train)

outlier.boxplot <- ggplot(melt.train, aes(variable, value)) +
  geom_boxplot(width=.5, fill="#58BFFF", outlier.colour="red", outlier.size = 1) +
  stat_summary(aes(colour="mean"), fun.y=mean, geom="point",
               size=2, show.legend=TRUE) +
  stat_summary(aes(colour="median"), fun.y=median, geom="point",
               size=2, show.legend=TRUE) +
  coord_flip(ylim = c(0, 110), expand = TRUE) +
  scale_y_continuous(labels = scales::comma,
                     breaks = seq(0, 110, by = 10)) +
  labs(colour="Statistics", x="", y="") +
  scale_colour_manual(values=c("#9900FF", "#3300FF")) +
  theme(panel.background=element_blank(), legend.position="top")


#  Missing Values
na.barplot <- plot_missing(train)

# Boxplots
boxplots <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x=factor(target), y=val)) +
    geom_boxplot(width=.5, fill="#58BFFF", outlier.colour="red", outlier.size = 1) +
    stat_summary(aes(colour="mean"), fun.y=mean, geom="point",
                 size=2, show.legend=TRUE) +
    stat_summary(aes(colour="median"), fun.y=median, geom="point",
                 size=2, show.legend=TRUE) +
    facet_wrap(~ var, scales = "free", ncol=4) +
    labs(colour="Statistics", x="", y="") +
    scale_colour_manual(values=c("#9900FF", "#3300FF")) +
    theme(panel.background=element_blank())

# DATA PREPARATION <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

# Correlation

correl2 <- train %>%
  select(-target) %>%
  cor() %>%
  round(2) %>%
  corrplot(method = "circle")
  
# Our transformation function
scaleFUN <- function(x) sprintf("%.2f", x)

Hist_log_new <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x = val, fill=factor(target))) +
    geom_histogram(position="dodge", bins=10, alpha=0.5) +
    facet_wrap(~ var, scales = "free") +
    scale_y_continuous(trans = "log", label=scaleFUN) +
    scale_fill_manual("target",values = c("#58BFFF", "#3300FF")) +
    xlab("") +
    ylab("") +
    theme(panel.background = element_blank())
  
# Linearity at log10 scale

linearity_log_new <- train %>%
    gather(-target, key = "var", value = "val") %>%
    ggplot(aes(x=factor(target), y=val)) +
    geom_boxplot(width=.5, fill="#58BFFF", outlier.colour="red", outlier.size = 1) +
    scale_y_continuous(trans = "log", label=scaleFUN) +
    stat_summary(aes(colour="mean"), fun.y=mean, geom="point",
                 size=2, show.legend=TRUE) +
    stat_summary(aes(colour="median"), fun.y=median, geom="point",
                 size=2, show.legend=TRUE) +
    facet_wrap(~ var, scales = "free", ncol=4) +
    labs(colour="Statistics", x="", y="") +
    scale_colour_manual(values=c("#9900FF", "#3300FF")) +
    theme(panel.background=element_blank())
    
# BUILD MODELS <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

## Model 1

## Build the model
model.1 <- glm(target ~ .,
               family = binomial,
               data = train) # + 0 removes intercept
#
mod.1 <- train(target ~., data = train,
                 method = "glm",
                 family = "binomial",
                 preProcess = c("center", "scale")) 
                 # center and scale data based on the mean and sd

mod1_summary <- summary(mod.1)
mod1_summary_a <- summ(model.1, vifs = TRUE)

### Model 1 Summary Statistics
pred.1.raw <- predict(mod.1, newdata = train)
pred.1 <- as.factor(ifelse(pred.1.raw < .5, 0, 1))
mod1.conf.mat <- confusionMatrix(pred.1,
                                 as.factor(train$target), mode = "everything")

#===============================================================================#
## Model 2

## Build the model
model.2.raw <- glm(target ~ zn + indus + chas + nox + rm + age + dis + rad + tax +
                     ptratio + lstat + medv + log(age) + log(dis) + log(nox) +
                     log(rad) + log(tax) + log(indus) + log(ptratio),
               family = binomial,
               data = train)

mod2_summary_raw <- summ(model.2.raw, vifs = TRUE)

model.2.step <- step(model.2.raw, trace=FALSE)
mod2_summary_step <- summ(model.2.step, vifs = TRUE)

model.2 <- glm(target ~ indus + nox + rm + age + dis + rad + tax + ptratio + medv +
                     log(age) + log(dis) + log(tax) + log(ptratio),
                     family = binomial, data = train)

mod2_summary <- summary(model.2)
mod2_summary_a <- summ(model.2, vifs = TRUE)

#marg_mod_plot_2 <- mmps(model.2, layout=c(5,4), key=NULL) # library car

### Model 2 Summary Statistics
pred.2.raw <- predict(model.2, newdata = train)
pred.2 <- as.factor(ifelse(pred.2.raw < .5, 0, 1))
mod2.conf.mat <- confusionMatrix(pred.2,
                                 as.factor(train$target), mode = "everything")

#===============================================================================#

## Model 5

#big_mod5 <- glm(target ~ (zn + indus + chas + nox + rm + age + dis + rad + tax + 
#                            ptratio + lstat + medv)^2, data = train, family = binomial)

#small_mod5 <- step(big_mod5, trace=FALSE)

# The above code is VERY computationally expensive
# Here's the result so it doesn't need to be run again.
model.5 <-  glm(formula = target ~ zn + indus + chas + nox + rm + age + dis +
                    rad + tax + ptratio + lstat + medv + zn:age + zn:tax + zn:ptratio +
                    zn:lstat + indus:chas + indus:rad + indus:ptratio + indus:medv +
                    nox:age + nox:tax + nox:ptratio + nox:lstat + nox:medv +
                    rm:age + age:tax + age:ptratio + dis:tax + dis:ptratio+
                    dis:lstat + dis:medv + rad:tax + tax:medv + lstat:medv, 
                    family = binomial,
                    data = train)

mod5_summary <- summary(model.5)
mod5_summary_a <- summ(model.5, vifs = TRUE)

#resid_plot_5 <- residual.plots(model.5, exclude = 4, layout = c(2, 2)) # library car

#marg_mod_plot_5 <- mmps(model.5, span = 3/4, layout = c(2, 2)) # library car

### Model 5 Summary Statistics
pred.5.raw <- predict(model.5, newdata = train)
pred.5 <- as.factor(ifelse(pred.5.raw < .5, 0, 1))
mod5.conf.mat <- confusionMatrix(pred.5, as.factor(train$target), mode = "everything")


#===============================================================================#
## Model 6

## Build the model
less_than_five <- function(x) ifelse(x < 5, x, 0)
five_and_over <- function(x) ifelse(x >= 5, x, 0)

model.6.raw <- glm(target ~ (less_than_five(rad) + five_and_over(rad)) + zn + indus + chas + 
                       nox + rm + age + dis + tax + ptratio + lstat + medv + log(age) +
                       log(dis) + log(tax) + log(ptratio) + indus:nox + indus:dis +
                       indus:tax+ nox:age + nox:dis + rm:medv + dis:age,
                   family = binomial,
                   data = train)
mod6_summary_raw <- summ(model.6.raw, vifs = TRUE)
backward.mod <- step(model.6.raw, direction = "backward", trace=FALSE)
backward_sum <- summary(backward.mod)

#forward.mod <- step(model.6.raw, direction = "forward", trace=FALSE)
#forward_sum <- summary(forward.mod)

model.6 <- glm(target ~ less_than_five(rad) + five_and_over(rad) +
                    zn + indus + nox + rm + age + tax + ptratio +
                    log(dis) + log(tax) + log(ptratio) + indus:dis + rm:medv +
                    age:dis + 0, family = binomial, data = train) # + 0 removes intercept

mod6_summary <- summary(model.6)
mod6_summary_a <- summ(model.6, vifs = TRUE)
### Model 6 Summary Statistics
pred.6.raw <- predict(model.6, newdata = train)
pred.6 <- as.factor(ifelse(pred.6.raw < .5, 0, 1))
mod6.conf.mat <- confusionMatrix(pred.6, as.factor(train$target), mode = "everything")

mod.6 <- train(target ~ less_than_five(rad) + five_and_over(rad) +
                 zn + indus + nox + rm + age + tax + ptratio +
                 log(dis) + log(tax) + log(ptratio) + indus:dis + rm:medv +
                 age:dis + 0,
               family = binomial,
               data = train,
               method = 'glm') # + 0 removes intercept

#===============================================================================#

## Model Evaluations

eval_mods <- data.frame(mod1.conf.mat$byClass,
                   mod2.conf.mat$byClass,
                   mod5.conf.mat$byClass,
                   mod6.conf.mat$byClass) # add additional model stats

eval_mods <- data.frame(t(eval_mods))
row.names(eval_mods) <- c("Model.1", "Model.2", "Model.3", "Model.4") # add additional models

eval_mods <- dplyr::select(eval_mods, Sensitivity, Specificity, Precision, Recall, F1)


# SELECT MODELS <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

#Pseudo R2

pseudo.r2 <- data.frame(pscl::pR2(model.1),
                        pscl::pR2(model.2),
                        pscl::pR2(model.5),
                        pscl::pR2(model.6))

pseudo.r2 <- data.frame(t(pseudo.r2))

row.names(pseudo.r2) <- c("Model.1", "Model.2", "Model.3", "Model.4")
```